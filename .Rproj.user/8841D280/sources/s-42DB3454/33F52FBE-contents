--- 
title: "A Short Introduction to Applied Statistical Programming in R"
author: "Robert Schnitman"
date: "`r paste0('March 29, 2020 (Last updated: ', format(Sys.Date(), '%B %d, %Y'), ')')`"
site: bookdown::bookdown_site
url: 'https\://rs-aspr.netlify.com/'
output: 
  bookdown::gitbook: 
    config:
      toc:
        collapse: section
      search: yes
      fontsettings:
        theme: sepia
      download: ["PDF"]
  bookdown::pdf_book: default
documentclass: book
biblio-style: apalike
link-citations: yes
github-repo: robertschnitman/aspr
description: "The purpose of this book is to teach students of social science statistics courses how to program in R for data analysis."
cover-image: "img/cover_image.jpg"
tags:
  - statistics
  - statistical computing
  - r programming
  - textbook
---


```{r setup, include = FALSE}
# Load libraries
library(knitr)
library(kableExtra)
```


```{r, echo = FALSE}
# Summary Table
summ <- function(data, caption) {
  
  summ_dat <- kable(data, 
                    booktabs = TRUE, 
                    caption  = caption,
                    linesep  = '') %>%
    kable_styling(full_width    = TRUE, 
                  latex_options = "hold_position") %>%
    row_spec(1:(NROW(data)-1), 
             hline_after = TRUE)
  
  summ_dat
  
}
```

# Introduction {-#index}

The purpose of this book is to teach students of social science statistics courses how to program in R for data analysis. Primarily focusing on Base R, this book will teach R "from the ground up," teaching the fundamentals without using external packages unless necessary or for quick demonstrations on the programming language's extensions. Overall, I hope that students will learn enough from this book to conduct data analysis in R independently.

Because I know people live busy lives, please feel free to skip chapters or simply only review the *Summary* subsections at the end of them--they are for your benefit!

Also, please feel free to email me at robertschnitman@gmail.com if you have any suggestions on improving this book!

![](img/cover_image.jpg)

# Prerequisites {-}

This book assumes that you have installed at least R version 3.6 at minimum (https://cran.r-project.org/). Installing the R Studio IDE afterward is strongly recommended (https://rstudio.com/products/rstudio/). Additionally, the focus of this book is more on programming in R rather than going in depth with the statistics--please consult your statistics textbook for the latter purpose instead.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

# The Paradigms of R

There are three main programming paradigms--or styles--that R uses: Array Programming (AP), Functional Programming, and Object Oriented (OOP). Knowing how these paradigms work is important, as they will help one understand the syntax structure of R.

## Array

The Array Programming (AP) paradigm allows us to access elements in a dataset via a matrix-like syntax.

```{r}
# Select the 2nd row and 5th column
#   from mtcars, which is a pre-loaded dataset.
mtcars[2, 5]

# Select the first 5 rows and all columns
mtcars[1:5, ]
```

## Functional

Much like Excel, R has functions: execution statements with an input and an output--this syntax style is called Functional Programming (FP).

```{r}
# Mean of MPG from the mtcars dataset
mean(mtcars$mpg) # $ accesses MPG from mtcars.

# Input  = mtcars$mpg
# OUtput = numeric value
```

Just like in math and Excel, we can compose multiple functions together.

```{r}
# Rounding the mean MPG by 2 digits.
round(mean(mtcars$mpg), 2)
```


## Object Oriented

In R, we can create and access objects, which are a storage of information with attributes: this paradigm is called Object Oriented Programming (OOP). This paradigm is concerned about classes and types--the "foreground" and "background" characteristics of a dataset, so to speak. Classes affect how data look to the user, whereas types are the specific attributes of some data.

Classes and types are discussed in the *Basics* chapter.

```{r}
# Access the MPG variable from mtcars
#   and save it to an object named "x"
x <- mtcars$mpg

# We can now refer to mtcars$mpg anytime with "x"
x 
```

We can check the structure of our data objects to know their attributes.

```{r}
# Check the structure of mtcars.
# A data frame composed of numeric vectors.
str(mtcars) 
```


## Summary

```{r, echo = FALSE}
summ_p <- data.frame(Paradigm    = c('Array', 
                                     'Functional',
                                     'Object Oriented'),
                     Description = c('Bracket syntax structure to access data like a matrix',
                                     'Mathematical function syntax structure to compute over data.',
                                     'Syntax structure in which data has stored attributes that affect how they look to the user.'),
                     Example     = c('mtcars[2, 5]',
                                     'mean(mtcars$mpg)',
                                     'str(mtcars)'))

summ(summ_p, 'Summary of Paradigms')
```


# Basics

In this chapter, we will learn how to use R as a calculator; learn the different data types and classes in R; learn how to make assignments; and learn how to get help when you are stuck on a particular issue.

## R as a calculator

You can use R like a calculator: the arithmetic operators are `+`, `-`, `*`, `/`, `^` (exponentiation), and `%%` (modular arithmetic)--there are more, but these operators are the basic ones (see more by typing `?'+'` into your console).

### Operators

```{r}
2+2  # Addition
2-2  # Subtraction
2*2  # Multiplication
2/2  # Division
2^2  # Exponentiation
2%%2 # Modular arithmetic
```


## Data Types and Classes
Classes are the "foreground" and types are the "background" characteristics of data. Classes affect how data look to the user, whereas types are the specific attributes of some data. We can check the class of an object with the `class()` function and type with the `typeof()` function.

Additionally, we can test to see if some data are a particular class or type with the `is.*()` and convert them with `as.*()`, where `*` can represent the classes and types that follow.

### Classes
There are many classes--some pre-defined in R, while others have been created externally. The three main classes (besides the `numeric` and `character` vector class, which are also types) are the `matrix`, `list`, and `data frame`.

```{r, echo = FALSE}
summ_class <- data.frame(Type = c('matrix',
                                  'list',
                                  'data frame'),
                         Decsription = c('A 2-dimensional array of elements, where each column is of the same type.',
                                         'A collection of elements, where each one can be a different type or class.',
                                         'A 2-dimensional set of elements, where each column can be a different type.'),
                         Example     = c('matrix(1:9, 3, 3)',
                                         'list(1, "a", matrix(1:9, 3, 3)',
                                         'mtcars'))

summ(summ_class, 'Summary of Classes')

```

### Types
```{r, echo = FALSE}
summ_types <- data.frame(Type = c('numeric',
                                  'character',
                                  'logical',
                                  'factor'),
                         Decsription = c('A vector of numbers.',
                                         'A vector of strings (i.e. characters encased in quotes.',
                                         'Value of TRUE or FALSE.',
                                         'A categorical vector with specified levels.'),
                         Example     = c('2',
                                         '"String"',
                                         'TRUE',
                                         'factor(mtcars$am)'))

summ(summ_types, 'Summary of Types')

```

## Assignments

Making assignments in R allows us to save information into an object, which further allows us to refer to a specific value without having to recalculate it each time.

```{r}
x <- 2

x
```

For a more complex example, we will run a regression model, save it to an object, and pass it to the `summary()` function to get more information from our model besides just its coefficients--we'll learn more about regressions in the *Linear Modeling* chapter.

```{r}
my_model <- lm(mpg ~ wt + hp + am, mtcars)

summary(my_model)
```

### Adding/Removing Variables

There are two main ways we can add variables to our dataset: (1) the `$` ("accessor"/dollar-sign) method and (2) the `transform()` method.

```{r}
mydata <- mtcars # copy data

# Let's create a variable called "my_new_var"
mydata$my_new_var <- with(mtcars, mpg/wt)

# Alternatively, the right-hand side
#   could be written as mtcars$mpg/mtcars$wt.

# Show a few rows from our dataset
head(mydata)
```

```{r}
# Let's do it again but with transform().
mydata2 <- transform(mydata, my_new_var = mpg/wt)

head(mydata2)
```

To remove variables, we assign them to be `NULL`.

```{r}
mydata$my_new_var <- NULL

head(mydata)
```

## Viewing Data

We can view data like an Excel spreadsheet in a separate window in R (or separate tab in RStudio) via the `View()` function. Try it out in your console!

```{r, eval = FALSE}
View(mtcars)
```


## Getting Help

There are two main ways of getting help in R: (1) using the `?` operator to access a function's documentation and (2) Googling your questions OR searching for them on StackOverflow--when you're beginning R, chances are that the problems you encounter have been solved.

```{r, eval = FALSE}
# Accessing the documentation for the mean function.
?mean
```

## Summary

```{r, echo = FALSE}
summ_basics <- data.frame(Functionality = c("+,-,*,/,^/%%",
                                            "Types/Classes",
                                            "Assignments",
                                            'Viewing data',
                                            "Getting help"),
                          Description   = c("Arithmetic operators",
                                            "Attributes of an object.",
                                            "Storing a value into an object.",
                                            "How to view your dataset like an Excel spreadsheet.",
                                            "How to look for help."),
                          Example       = c("2+2",
                                            "str(mtcars); class(mtcars); typeof(mtcars$mpg)",
                                            "x <- 2",
                                            "View(mtcars)",
                                            "?mean; Google/StackOverflow"))

summ(summ_basics, "Summary of Basics")
```


# Data Management

In this chapter, we will learn how to replace values, switch values, import data, combine data, subset data, and split data.

## Replacing Values

We can replace values with the `replace()` function.

```{r}
x <- 1:10 # 1 through 10.

# If x equals 2, 5, or 7, replace with 0.
## replace(vector, condition, replacement value).
replace(x, x %in% c(2, 5, 7), 0)
```
## Switching Values

We can switch--or recode--values with the `switch()` function. By default, `switch()` is a "scalar" function in that it only produces a single value. To produce a vector of values, we combine it with `sapply()`--see the *Functionals* chapter for more details on `sapply()`.

### Scalar Case
In the case of a single value, all we need to pass into `switch()` are (1) the data object and (2) an expression stating what the old value should become (i.e, provide the old value and the replacement value).

```{r}
# SYNTAX OF switch():
## switch(x, old_value = new_value)

x <- "a"

xs <- switch(x, a = 1)

xs
```

### Vector Case

For the case of applying `switch()` to vectors, we make use of `sapply()`.

To take a case in point, let's first generate some random data of racial groups.

```{r}
set.seed(1) # Remember our random sampling

# Generate vector of unique values.
my_vector <- c('Asian', 'African American', 'White', 'Other')

# Conduct repeat sampling of my_vector
## See the Probability Functions chapter for more details on sample().
my_vector2 <- sample(my_vector, 20, replace = TRUE)

# Print the new vector.
my_vector2
```

Let's say that we want to recode these values: 0 for *White*, 1 for *African American*, 2 for *Asian*, and 3 for *Other*. To do so, we first define a function and pass it through `sapply()`--see the *Function Writing* and *Functionals* chapters respectively for more information.

```{r}
# First, define a function that recodes the races into integers.
my_switch <- function(v) {
  
  switch(v, White = 0, `African American` = 1, Asian = 2, Other = 3)
  # We use back quotes for "African American" because of the space.
  
}

# Now we can pass my_switch to sapply() to execute the recoding.
sapply(my_vector2, my_switch)
```


## Importing Data

We can import datasets with `read.table()`--this method is the most general.

```{r}
# Set path to dataset
# For this example, our data is in the data folder
#  and our data are separated by commas.
my_data <- read.table('data/mtcars.csv', sep = ',', stringsAsFactors = FALSE)

# Setting stringsAsFactors = FALSE maintains strings as strings.
## See the Basics chapter for more detail on classes and types.
```

In the case of files with comma-separated values, we can use `read.csv()` to import them more easily.

```{r}
# Set path to dataset
my_data <- read.csv('data/mtcars.csv', stringsAsFactors = FALSE)
```


## Combining Data

There are three main ways to combine data: (1) `cbind()`, (2) `rbind()`, and (3) `merge()`. 

### `cbind()`/`rbind()`

The function `cbind()` combines vectors or datasets column-wise, while `rbind()` does so row-wise.

```{r}
x <- 1:5
y <- 6:10

cbind(x, y)
rbind(x, y)
```

### `merge()`

Merging data with `merge()` (AKA "joining data") is powerful, as we can combine disparate datasets that have a common linking variable between them.

```{r}
set.seed(1) # remember our random numbers from rnorm().

data1 <- data.frame(survey_id = 1:5, 
                    wage      = rnorm(5, mean = 15, sd = 5))

data2 <- data.frame(survey_id  = 5:1,
                    experience = rnorm(5, mean = 5, sd = 3))

# merge(first data, second data, by = 'a common variable').
data_merge <- merge(data1, data2, by = 'survey_id')

data_merge # An "inner-join" of datasets
```

What we accomplished here is an *inner join*: a join in which two datasets overlap. See the documentation file for `merge()` for more information on different types of joins (i.e., type `?merge` into the R console).

## Subsetting Data

To subset data, we can pass data and relational/logic operators[^1] into the `subset()` function, or we can use the bracket syntax and use the operators there.

The relational operators are the following:

* `<`, `>`, `<=` (less than or equal to), `>=` (greater than or equal to)

* `==` (equal to), `!=` (not equal to)

The main logic operators are the following:

* `&` (and)

* `|` (or)

[^1]: "binary operators" that compare values (R Documentation, Comparison). See `?Comparison` for more information. For logic operators, see `?Logic`.

### Vector Case

Suppose we have the following vector:

```{r}
x <- -10:10 # integers from -10 to 10.
x
```

Then we can subset like the following:

```{r}
x[x < 0] # same as subset(x, x < 0)

x[x > 2 & x < 5]

# We can use functions inside the brackets.
## For example, %in% is a matching function:
##   let's use it to subset for only 1 through 5.
x[x %in% 1:5] 
```

### Data Frame Case

Suppose the dataset `mtcars`. Then we can subset like the following:

```{r}
subset(mtcars, mpg > 30) # Same as mtcars[mtcars$mpg > 30, ]

subset(mtcars, mpg > 30 & wt > 1.7)
```

## Splitting Data

To split data, we pass a data frame and a variable into the `split()` function.

```{r}
split(mtcars, mtcars$gear) # Splits into 3 subsets.
```

Splitting can be useful when you want to apply a function that's contingent on subsets of data. For example, we can split the data and perform a regression model on each of them.

```{r}
# 1. Split dataset by a splitting variable.
my_split <- split(mtcars, mtcars$gear)

# 2. Estimate a regression model based on each subset.
my_models <- lapply(my_split, function(data) lm(mpg ~ wt, data))

# 3. Print the coefficients in a matrix form.
sapply(my_models, coef)
```

For more information about `lapply()` and `sapply()`, see the *Functionals* chapter; for more information about `lm()`, see the *Linear Modeling* chapter.

## Summary

```{r, echo = FALSE}
summ_dm <- data.frame(Function    = c('replace(x, condition, replacement)',
                                      'switch(x, expression)',
                                      "read.table('path/to/file.csv', sep = ',')",
                                      'cbind(x,y)/rbind(x,y)',
                                      "merge(x, y, by = 'linking_var')",
                                      "subset(data, condition); x[condition]",
                                      "split(data, grouping_variable)"),
                      Description = c("Replace a value in a vector based on a condition.",
                                      "Switch (recode) values.",
                                      "Import a dataset.",
                                      "Combine data column- or row-wise.",
                                      "Join data by a linking variable.",
                                      "Subset data via relational and logic operators.",
                                      "Split data by a grouping variable"),
                      Example     = c("x <- 1:10; replace(x, x %in% c(2, 5, 7), 0)",
                                      "x <- 'a'; switch(x, a = 1)",
                                      "my_data <- read.table('data/mtcars.csv', sep = ',')",
                                      "x <- 1:5; 
                                      y <- 6:10;
                                      cbind(x, y); 
                                      rbind(x,y)",
                                      "data1 <- data.frame(survey_id = 1:5, 
                    wage      = rnorm(5, mean = 15, sd = 5))

data2 <- data.frame(survey_id  = 5:1,
                    experience = rnorm(5, mean = 5, sd = 3)) \n
data_merge <- merge(data1, data2, by = 'survey_id')",
"subset(mtcars, mpg > 30 & wt > 1.7)",
"split(mtcars, mtcars$gear)"))

summ(summ_dm, "Summary of Data Management Functions")
```


# String Functions

String functions allow us to combine, pattern-match, and substitute character vectors.

## Concatenate Strings

There are two concatenation functions we can use: `paste()` and `paste0()`. The former assumes you want to separate the concatenated elements with a space, whereas the latter will assume no separation.

```{r}
paste('a', 'b')
paste('a', 'b', sep = '-')
paste0('a', 'b')
```

## Subset Strings

In Excel, we can subset strings with `LEFT()`, `MID()`, and `RIGHT()`. In R, we can subset strings with `substr()`/`substring()`, which both act similarly as `MID()` from Excel.

```{r}
x <- 'Albatross'

substr(x, 1, 4)

substring(x, 5) # Goes to the end by default
```


## Split Strings

We can split strings with the `strsplit()` function.

```{r}
x <- c('This is a sentence.', 
       'This is another sentence.',
       'This is yet another sentence.')

# Split vector elements by space
my_split <- strsplit(x, split = ' ') 

# Output is a list
my_split 
```

We can use `do.call()` and `c()` to combine these list elements into a single vector for a total of `r length(do.call(c, my_split))` elements. The function `do.call()` iteratively executes a function and `c()` ("combine") combines elements into a vector.

```{r}
do.call(c, my_split)
```


## Substitute Strings

We can make character substitutions with `gsub()`.

```{r}
x <- c('This is a sentence.', 
       'This is another sentence.',
       'This is yet another sentence.')

gsub('sentence', 'drink', x)
```


## Match String Patterns

We can pattern-match strings with `grep()` and `grepl()`. The former outputs the position (or value) of a pattern match, while the latter outputs a Boolean value (i.e. `TRUE`/`FALSE`).

```{r}
# Cars that start witih "M"
grep('^M', rownames(mtcars), value = TRUE)

# Which cars start with and do not start with "M"?
grepl('^M', rownames(mtcars))

# Selecting columns that start with "m".
# We set drop = FALSE to maintain a data frame.
head(mtcars[, grep('^m', names(mtcars)), drop = FALSE])
```

Check out more regular expressions with [RStudio's cheat sheet on strings](https://github.com/rstudio/cheatsheets/blob/master/strings.pdf).

## Summary

```{r, echo = FALSE}
summ_strings <- data.frame(Function = c('paste(x, y)/paste0(x, y)',
                                        'substr(x, start, end)',
                                        "strsplit(x, split = ' ')",
                                        'gsub(pattern, replacement, x)',
                                        'grep/grepl(pattern, vector)'),
                           Description = c('Concatenation of x and y.',
                                           "Subset strings.",
                                           'Split a string by a splitting character.',
                                           'Substitute a portion of a string vector based on a given pattern.',
                                           'Pattern match a string and output its position OR Boolean (i.e. TRUE/FALSE).'),
                           Example = c("paste('a', 'b'); paste0('a', 'b')",
                                       "substr('Albatross', 1, 4)",
                                       "x <- c('This is a sentence.', 
       'This is another sentence.',
       'This is yet another sentence.')
\n strsplit(x, split = ' ')",
"gsub('sentence', 'drink', 'This is a sentence.')",
"grep('^M', rownames(mtcars), value = TRUE)"))

summ(summ_strings, 'Summary of String Functions')
```


# Control Flow

Control flow statements allow us to control the flow of our script or data. This functionality is useful for when we want different results depending on specific conditions.

## `if` and `ifelse()`

The `if` statement controls the flow of *your R script*, branching out to different possibilities if a condition is not met.

```{r}
x <- 2

if (x == 2) {
  
  'x is 2!'
  
} else if (x == 3) {
  
  'x is 3!'
  
} else {
  
  'x is not 2 nor 3!'
  
}
```


The `ifelse()` function, on the other hand, controls the flow of *your vector*.

```{r}
x <- c(1:10)

# If x is divisible by 2, then "even"; else, "odd."
ifelse(x %% 2 == 0, paste0(x, ': even'), paste0(x, ': odd'))
```

## Loops

Loops allow the user to operate on data iteratively, which is useful for reducing repetitive code.

### `for` loop

In a `for` loop, we iterate over data *for each* data element in a sequence.

```{r, eval = FALSE}
# Structure of a for loop
x <- c() # empty vector or list.

# For each data element in some_data...
for (i in seq_along(some_data)) {
  
  do_something(some_data[, i]) 
  # The "i" represents the column position in this case.
  
}
```

Let's take this example: getting the means for each column in the dataset `mtcars`, which is pre-loaded into R.

```{r}
# Getting the means for each column in mtcars.

## Create an empty vector into which we will
##   store means.
x <- c()

## For each variable in mtcars...
for (i in seq_along(mtcars)) {

  ### Store the mean of that variable
  ###   into x.
  x[i] <- mean(mtcars[, i])

}

x
```

There is actually a much better way to get the means of all columns in a dataset, which will be discussed in the *Functionals* chapter. In the meantime, the following is a more complex use-case of a `for` loop.

```{r, fig.pos = "H"}
# set 4x3 canvas
par(mfrow = c(2, 3)) 

# For each column in the dataset iris...
for (i in seq_along(iris)) {
  
  # Plot a histogram.
  hist(mtcars[, i], # Get column vector.
       xlab = names(iris)[i], # Get name of column.
       ylab = 'Frequency',
       col  = 'cyan4',
       # Set the title to be based on the column name.
       main = paste(names(iris[i]), 'Distribution'))
  
}
```

For more on graphs, see the *Graphing* chapter.

### `while` loop

In contrast to the `for` loop, the `while` loop iterates over data until the specified condition breaks (i.e., no longer true).

```{r}
# Set an initial value for the while loop.
x <- 0

# While x is less than 10...
while (x < 10) {
  
  # Add 1 to it...
  x <- x + 1
  
  # And then print it to the console.
  print(x)
  
}

```

## Summary

```{r, echo = FALSE}
funs <- data.frame(`Statement or Function` = c('if (condition) {output}',
                                   'ifelse(test, yes, no)',
                                   'for (statement) {output}',
                                   'while (condition) {output}'),
                   Description = c("Control the flow of the R script.",
                                   "Control the flow of a vector.",
                                   "Iterate over each data element.",
                                   "Iterate over data until a condition breaks."),
                   Example = c("if (x == 2) {'x is 2!'} else {'x is not 2!'}",
                               "ifelse(1:10 %% 2 == 0, 'even', 'odd')",
                               "x <- c();

for (i in seq_along(mtcars)) {

  x[i] <- mean(mtcars[, i])

};

x",
                               "x <- 0;

while (x < 10) {
  
  x <- x + 1
  
  print(x)
  
}"))



summ_funs <- summ(funs, caption = 'Control Flow Statements')

summ_funs
```


# Descriptive Statistics

The following is a list of summary statistics functions. Try them out in your console!

```{r, echo = FALSE}
funs <- data.frame(Function = c('mean(x)',
                                'sd(x)',
                                'median(x)',
                                'min(x)',
                                'max(x)',
                                'nrow(x)/NROW(x)',
                                'ncol(x)/NCOL(x)',
                                'dim(x)',
                                'length(x)',
                                'summary(x)',
                                'table(x)',
                                'prop.table(table)'),
                   Description = c('Computes the mean.',
                                   'Computes the standard deviation.',
                                   'Computes the median.',
                                   'Computes the minimum.',
                                   'Computes the maximum.',
                                   'Computes the number of rows.',
                                   'Computes the number of columns.',
                                   'Computes the number of rows and columns.',
                                   'Computes the number of elements in a data object.',
                                   'Summarizes a dataset.',
                                   'Generates a frequency table for one or more variables.',
                                   'Generates a proportions table.'),
                   Example     = c('mean(mtcars\\$mpg)',
                                   'sd(mtcars\\$mpg)',
                                   'median(mtcars\\$mpg)',
                                   'min(mtcars\\$mpg)',
                                   'max(mtcars\\$mpg)',
                                   'nrow(mtcars); NROW(mtcars)',
                                   'ncol(mtcars); NCOL(mtcars)',
                                   'dim(mtcars)',
                                   'length(mtcars\\$mpg)',
                                   'summary(mtcars)',
                                   'table(mtcars\\$gear); with(mtcars, table(gear, am))',
                                   'prop.table(table(mtcars\\$gear))'))



summ_funs <- summ(funs, caption = 'Summary of Descriptive Statistics Functions')

summ_funs
```

# Probability Functions

This chapter will primarily focus on the normal distribution functions in R.

## Generating Random Numbers
To calculate random numbers in R based on a normal distribution, we can use the `rnorm()` function. By default, the mean and sd respectively are 0 and 1; but we can change these parameters as necessary.

```{r, fig.pos = "H"}
set.seed(1) # Remember our random numbers
x <- rnorm(100,       # 100 random numbers
           mean = 50, # with a mean of 50
           sd = 20)   # and SD of 20.

plot(density(x),
     main = '100 Random Numbers')
```

See more on plots in the *Graphing* chapter.

## Sampling
We can take a random sampling of a vector with `sample()`.

```{r}
set.seed(1) # Remember our random values.

# 10 random numbers from 
#   a vector of 100 values.
sample(1:100, size = 10, replace = TRUE)
```

For a dataset, we can do the following:

```{r}
set.seed(1) # Remember our random values.

# Random 5 rows
mtcars[sample(1:NROW(mtcars), 5), ]
```


## Others
See `?rnorm`, `?rchisq`, and `?rpois` for more information on normal, chi-square, and Poisson probability distributions

## Summary

```{r, echo = FALSE}
summ_pd <- data.frame(Function = c("rnorm(x)",
                                   "sample(x, size)",
                                   "Other probability functions."),
                      Description = c("x random numbers based on a normal distribution.",
                                   "Sample a vector with a specified size.",
                                   "See `?rnorm`, `?rchisq`, and `?rpois`"),
                      Example = c("rnorm(10)",
                                   "sample(1:100, size = 10)",
                                   ""))

summ(summ_pd, 'Summary of Probability Distributions')
```

# Function Writing

Writing functions allows us to condense a process into a single function. 

## Univariate Case

If we wanted to index a variable by its mean, we could simply type `x/mean(x)`, where `x` is our vector. However, what if there were a function called `index()` that makes this process more clear? There is not one inherently in R, but we are able to create it:

```{r}
index <- function(x) { # the formals/arguments
 
  x/mean(x) # The body
  
}

index(mtcars$mpg)
```

We can cast this new function over all columns in `mtcars` with `sapply()`.[^2]

```{r}
# Get only a few rows.
head(sapply(mtcars, index))
```

[^2]: See the *Functionals* chapter for more on `sapply()` and its bretheren.

## Multivariate Case

In the univariate case, we indexed a vector by its mean. What if we wanted to use the median instead? We would simply need to replace `mean` with `median`. Alternatively, we can add an additional input into our function that specifies what aggregation function to use in the indexing.

```{r}
index2 <- function(x, f) {
  
  x/f(x)
  
}
```

Now we can use any function in the `f` input.

```{r}
head(index2(mtcars$mpg, mean)) # show only a few elements

head(index2(mtcars$mpg, median)) # show only a few elements

head(index2(mtcars$mpg, max)) # show only a few elements
```

Our `index2` function is actually special in that it is not only a multivariate function but a *functional*, which is a function that takes another function as an input--see the *Functionals* chapter for more details.

## Summary

```{r, echo = FALSE}
summ_fun <- data.frame(Function = c("function(x)"),
                       Description = c("Write a function, which consists of arguments and the body."),
                       Example = c("index <- function(x) x/mean(x)"))

summ(summ_fun, "Summary of Function Writing")
```



# Functionals

Functionals are functions that take a function as an input and output a value. They are useful for casting a function over all columns in a dataset or elements in a list.

This chapter will demonstrate a select handful of functionals--see `?lapply` for more information.

## `lapply()`
The `lapply()` function ("list apply") casts a function over a dataset and outputs a list.

```{r}
lapply(mtcars, mean)
```

## `sapply()`
The `sapply()` function ("simplified apply") casts a function over a dataset and outputs a matrix (or list, depending on the function).

```{r}
sapply(mtcars, mean)
```

## `apply()`
The `apply()` function can cast a function over a dataset row-wise or column-wise, returning a matrix.

```{r}
# Row-wise means.
# show only a few with head().
head(apply(mtcars, 1, mean))
```

```{r}
# Column-wise means.
apply(mtcars, 2, mean)
```


## `vapply()`

The `vapply()` function ("vectorized apply") works similarly as `sapply()`; however, there is a type-checking component to it. In other words, one can set whether the output should be numeric or character, for example, beforehand. If the output does not match the set type, an error will occur. This function is useful for type-checking your results (i.e., making sure the output matches your expectations).

```{r}
# Mean of all mtcars columns
# Type-check whether it is a numeric vector.
vapply(mtcars, mean, numeric(1))

```

```{r, error=TRUE}
# Mean of all mtcars columns
# Type-check whether it is a character vector.
vapply(mtcars, mean, character(1))
```

## `mapply()`/`Map()`

The functions `mapply()` and `Map()` allow us to compute a function iteratively over one or more data inputs. 

### Univariate Case

In the univariate case, `mapply()`/`Map()` work similarly as `sapply()`/`lapply()`.

```{r}
mapply(mean, mtcars)
```

```{r}
head(Map(mean, mtcars)) # Just show a few.
```

### Multivariate Case

In the multivariate case, we can have multiple data inputs.

```{r}
# Row bind mpg and wt from mtcars.
# Output = matrix
# Show only a few columns.
mapply(rbind, mtcars$mpg, mtcars$wt)[, 1:5]
```

```{r}
# Row bind mpg and wt from mtcars.
# Output = list.
# Show only a few rows.
head(Map(rbind, mtcars$mpg, mtcars$wt))
```

## `rapply()`

The `rapply()` function allows one to iterate over a list of datasets recursively. In other words, it allows us to compute the means for all datasets in a list simultaneously, for example.

```{r}
my_list <- list(mtcars, airquality, iris)

rapply(my_list, # For this list...
       # Get all means...
       mean,    
       # Remove missing values...
       na.rm = TRUE, 
       # Calculate only for numeric columns
       classes = 'numeric') 
```

## `aggregate()`

The function `aggregate()` allows you to make group-wise calculations.

```{r}
# Ge thte mean MPG by gear and am.
my_agg <- aggregate(mpg ~ gear + am, mtcars, mean)

my_agg
```


## Summary

```{r echo = FALSE}
funs <- data.frame(Function = c('lapply(X, FUN)',
                                'sapply(X, FUN)',
                                'apply(X, MARGIN, FUN)',
                                'vapply(X, FUN, FUN.VALUE)',
                                'mapply(FUN, ...)',
                                'Map(f, ...)',
                                'rapply(object, f, classes)',
                                'aggregate(formula, data, FUN)'),
                   Description = c('Compute a function over data and output a list.',
                                   'Compute a function over data and output a matrix (sometimes a list, depending on the function being passed).',
                                   'Compute a function row-wise or column-wise.',
                                   'Compute a function over data and check if the output matches a pre-specified type.',
                                   'Compute a function over one or more data inputs and output an array (vector or matrix).',
                                   'Compute a function over one or more data inputs and output a list.',
                                   'Recursively compute a function over data and output a vector or list.',
                                   'Generate grouped computations and output a data frame.'),
                   Example     = c('lapply(mtcars, mean)',
                                   'sapply(mtcars, mean)',
                                   'apply(mtcars, 1, mean); apply(mtcars, 2, mean)',
                                   'vapply(mtcars, mean, numeric(1))',
                                   'mapply(rbind, mtcars\\$mpg, mtcars\\$wt)',
                                   'Map(rbind, mtcars\\$mpg, mtcars\\$wt)',
                                   'rapply(iris, mean, classes = "numeric")',
                                   'aggregate(mpg ~ gear, mtcars, mean)'))



summ_funs <- summ(funs, caption = 'Summary of Functionals')

summ_funs
```


# Graphing

The following subsections show examples of how to create certain types of graphs.

## Histograms

All we need to make a histogram is to pass a vector into the `hist()` function.

```{r, fig.pos = "H"}
hist(mtcars$mpg, 
     col = 'cyan4',
     xlab = 'MPG',
     ylab = 'Frequency',
     main = 'MPG Distribution')
```

## Density Plots

```{r, fig.pos = "H"}
set.seed(1) # Remember our random numbers.

x <- density(rnorm(100))

plot(x,
     main = '100 Random Numbers',
     col  = 'salmon')
```


## Scatter Plots

To make a scatter plot, we make use of the `plot(formula)` function, where `formula` input is of the syntax `y ~ x` (y relates to the y-axis and relates to the x-axis).

### Simple Scatter Plot

```{r, fig.pos = "H"}
# Draw the scatter plot
with(mtcars,
     plot(mpg ~ wt,
          ylab = 'MPG',
          xlab = 'Weight',
          main = 'MPG vs. Weight',
          col = 'cyan4',
          pch = 16)) # pch determines point type.
     
# Draw a trend line over the scatter plot
abline(lm(mpg ~ wt, mtcars), 
       col = 'salmon',
       lwd = 2) # line width

```

### Multiple Scatter Plots

For a more complex example, let's make multiple scatter plots via a `for` loop.

```{r, fig.pos = "H"}
# Set up a 2x2 canvas
par(mfrow = c(2,2)) 

# Set parameters
unique_gears <- sort(unique(mtcars$gear))

mycolors <- c('cyan4', 'salmon','forestgreen', 'purple')

# Begin plot loop
for (i in seq_along(unique_gears)) {
  
  # Subset by number of gears
  ss <- subset(mtcars, gear == unique_gears[i])
  
  # Plot a scatter points
  with(ss,
       plot(mpg ~ wt,
            col = mycolors[i],
            ylab = 'MPG',
            xlab = 'Weight',
            main = paste0('MPG vs. Weight (No. of Gears = ',
                          unique_gears[i],
                          ')')))
  
  # Generate a trendline for each subset.
  abline(lm(mpg ~ wt, ss))
  
}
```

Notice how "purple" isn't used in graphs, as there are only three sub-graphs to plot

### Text Plot

To make a text plot, we just turn off the points in the `plot()` function via `type = 'n'` and then use the `text()` function to label them on the graph.

```{r}
# Set up basic plot.
with(mtcars, plot(wt ~ mpg, pch = 1, type = 'n',
                  xlab = 'MPG',
                  ylab = 'Weight',
                  main = 'Weight vs. MPG'))

# Plot the labels on the graph.
with(mtcars, text(mpg, # x coordinate for words
                  wt,  # y coordinate for words
                  row.names(mtcars), # Words to use.
                  pos = 3, 
                  cex = 0.0, 
                  col = 'cyan4'))

# Add some mean lines for flair.
abline(h = mean(mtcars$wt), v = mean(mtcars$mpg),
       lty = 2)
```


## Line Plots

Making a line plot is similar to making a scatter plot except that we set `type = 'l'` as an additional input.

```{r, fig.pos = "H"}
# Suppose we had this dataset:
set.seed(1) # Remember our random numbers.
df <- data.frame(y = rnorm(10),
                 x = 2000:2009)

# Plot this dataset
with(df, plot(y ~ x,
              type = 'l',
              col = 'salmon',
              ylab = 'Some Random Numbers',
              xlab = 'Year'))
```

## Box Plots

Constructing a box plot with the `boxplot()` function is similar to making a scatter plot with `plot()`: we pass a formula of vectors into it.

```{r, fig.pos = "H"}
with(mtcars,
     boxplot(mpg ~ gear,
             ylab = 'MPG',
             xlab = 'Number of Gears',
             main = 'Box Plot of MPG vs. Number of Gears',
             col  = 'grey'))
```


## Bar Plots

For a bar plot, we pass a vector (usually one of counts) or aggregation to `barplot().

### Frequency Chart
For a frequency chart, we have to calculate a table of frequencies with the `table()` function before passing it to `barplot()`.

```{r, fig.pos = "H"}
my_table <- table(mtcars$gear)

barplot(my_table,
        ylab = 'Frequency',
        xlab = 'Number of Gears',
        col  = 'lavender',
        main = 'Frequencies by Number of Gears')
```

### Grouped Mean Comparisons
For grouped mean comparisons, we have to aggregate data with `aggregate()` (see the `Functionals` chapter for more details) before passing it to `barplot()`.

```{r, fig.pos = "H"}
my_agg <- aggregate(mpg ~ gear, mtcars, mean)

with(my_agg, 
     barplot(mpg ~ gear, beside = TRUE,
             ylab = 'Mean MPG',
             xlab = 'Number of Gears',
             main = 'Mean MPG by Number of Gears',
             col  = 'lavender'))
```


## Summary

```{r, echo = FALSE}
funs <- data.frame(Function = c('hist(x)',
                                'plot(density(x))',
                                'plot(y ~ x)',
                                "plot(y ~ x, type = 'l')",
                                'boxplot(y ~ x)',
                                'barplot(x)'),
                   Description = c('Histogram',
                                   'Density plot',
                                   'Scatter plot',
                                   'Line plot',
                                   'Box plot',
                                   'Bar plot'),
                   Example     = c('hist(mtcars\\$mpg)',
                                   'plot(density(rnorm(100)))',
                                   'with(mtcars, plot(mpg ~ wt))',
                                   "with(Orange, plot(circumference ~ age, type = 'l'))",
                                   'with(mtcars, boxplot(mpg ~ wt))',
                                   'barplot(table(mtcars\\$gear))'))



summ_funs <- summ(funs, caption = 'Summary of Graphing Functions')

summ_funs
```

# Hypothesis Testing

In this chapter, we will cover how to conduct a t-test of means and chi-square test of frequencies.

## t-test

To conduct a t-test, we use the `t.test()` function. What we input into this function depends on whether we want to compute a one-sample or two-sample test.

### One-sample t-test

To conduct a 1-sample t-test, we pass a vector and a `mu` value into the `t.test()` function. The `mu` value is the number against which we will compare the vector's mean to determine whether there is a statistically significant difference.

```{r}
# Testing whether the mean MPG is statistically equal to 17.
t.test(mtcars$mpg, mu = 17)
```

### Two-sample t-test

To conduct a two-sample t-test, we use the formula syntax of `y ~ x`, where `y` is our continuous dependent variable and `x` is our categorical independent variable. Then, we pass this formula into `t.test()`.

```{r}
# Compare mean MPG by transmission type
with(mtcars, t.test(mpg ~ am))
```

## Chi-square test

To conduct a Chi-square test, we pass a two-way `table` into the `chisq.test()` function.

```{r}
mytable <- with(mtcars, table(gear, am))

mytable
chisq.test(mytable)
```

## Summary

```{r, echo = FALSE}
summ_tests <- data.frame(Function = c('t.test(x, mu)',
                                      't.test(y ~ x)',
                                      'chisq.test(table)'),
                         Description = c('Test of mean against mu.',
                                         'Test of group means.',
                                         'Test of two-way frequencies.'),
                         Example = c('t.test(mtcars$mpg, mu = 17)',
                                     'with(mtcars, t.test(mpg ~ am))',
                                     'with(mtcars, chisq.test(table(gear, am)))'))

summ(summ_tests, 'Summary of Hypothesis Testing')
```


# Linear Modeling

In this chapter, we will examine Pearson correlations, ANOVA, Ordinary Least Squares, and logistic regression.

## Pearson Correlations

To estimate a Pearson correlation for all variables in a dataset, we pass a `matrix` or `data frame` into the `cor()` function.

```{r}
# Pearson correlation coefficient matrix
cor(mtcars)
```

To perform a correlation test in which we produce a p-value, we pass two vectors into the `cor.test()` function.

```{r}
# Pearson correlation coefficient test
with(mtcars, cor.test(mpg, wt))
```

To get p-values from a correlation matrix for all variables, we will use the `Hmisc` package. We install it with `install.packages()` and then load it with `library()`. We use the library's `rcorr()` function to calculate the correlation and p-values matrices.

```{r eval = FALSE}
install.packages('Hmisc') # Install first.
```

```{r, message = FALSE, warning = FALSE, cache = TRUE}

# Load the library into the environment.
library(Hmisc)

my_corr <- rcorr(as.matrix(mtcars), type = 'pearson')

# Pearson correlation coefficients
my_corr$r

# p-values of the coefficients.
my_corr$P
```

## ANOVA

To conduct ANOVA, we pass a formula and dataset into the `aov()` function. Note that the independent variables must be `factor` variables, so we must use the `factor()` function on our independent variables if they are not already factors.

```{r}
my_anova <- aov(mpg ~ factor(gear) + factor(am), mtcars)

my_anova

summary(my_anova)
```

To compare pairwise means, we use `TukeyHSD()` on our ANOVA model.

```{r}
TukeyHSD(my_anova)
```

## Ordinary Least Squares

To estimate a regression model, we pass a formula and a dataset into the `lm()` function.

```{r}
# SYNTAX OF lm(): lm(y ~ x1 + x2 + ... xn, data)
my_ols <- lm(mpg ~ wt + hp + gear + am, mtcars)

# Return the coefficients
my_ols

# Produce a summary table of the results.
summary(my_ols)

# Return the coefficient table from the summary regression table.
coef(summary(my_ols))
```

### Residual diagnostics with OLS

To analyze the performance of our models with respect to our residuals, we can calculate the predicted values with `predict()` and residuals with `resid()`. We can then plot them to see whether the residuals behave in a homoskedastic manner.

```{r, fig.pos = "H"}
fit <- predict(my_ols)
res <- resid(my_ols)

plot(res ~ fit)
abline(lm(res ~ fit), lty = 2)
```

Alternatively, we can directly plot our model. Make sure to set a 2-by-2 canvas beforehand so that all the plots from `plot()` will generate simultaneously.

```{r, fig.pos = "H"}
par(mfrow = c(2,2)) # Set 2x2 canvas

plot(my_ols)
```


## Logistic Regression
Estimating a logistic regression is similar to estimating a model with OLS; however, we add an additional input in which we set the distribution family--in this case, it is the binomial one.

```{r}
my_logit <- glm(am ~ mpg + wt + gear, 
                mtcars, 
                family = binomial(link = 'logit'))

my_logit

summary(my_logit)
```

## Summary

```{r, echo = FALSE}
summ_lm <- data.frame(Function = c('cor(data)',
                                   'rcorr(data)',
                                   'aov(y ~ x, data)',
                                   'TukeyHSD(anova)',
                                   'lm(y ~ x, data)',
                                   'glm(y ~ x, data, family)'
                                   ),
                      Description = c("Correlation matrix.",
                                      "Correlation matrix with p-values.",
                                      "ANOVA.",
                                      "Tukey HSD pairwise means.",
                                      "Linear Modeling / Ordinary Least Squares modeling.",
                                      "Generalized Linear Model."),
                      Example = c('cor(mtcars)',
                                  "library(Hmisc); 
rcorr(as.matrix(mtcars), type = 'pearson'",
'aov(mpg ~ factor(gear), mtcars)',
'TukeyHSD(aov(mpg ~ factor(gear), mtcars))',
'lm(mpg ~ wt + gear, mtcars)',
"glm(am ~ mpg + gear, mtcars, family = binomial(link = 'logit'))"))

summ(summ_lm, 'Summary of Linear Modeling')
```


# Recommended R Libraries

The following is a list of recommended R libraries to install--they can be helpful for data management, graphing, and formatting.

## `tidyverse`

The `tidyverse` package is a metapackage consisting of other libraries. The most useful ones for a beginner, I believe, are `ggplot2`, `dplyr`, `tidyr`, and `purrr`.

For more information, see the [`tidyverse` website](https://www.tidyverse.org/).

```{r eval = FALSE}
install.packages('tidyverse')
```

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
```

### `ggplot2`

The library `ggplot2` offers visualization tools with a modern aesthetic. The following is an example of a small-multiples[^3] scatter plot. For more information, see the [`ggplot2` website](https://ggplot2.tidyverse.org/).

[^3]: https://en.wikipedia.org/wiki/Small_multiple

```{r, fig.pos = "H"}
ggplot(mtcars) + 
  aes(y = mpg, x = wt, col = factor(am), size = hp) + 
  geom_point(alpha = 0.5) + 
  labs(y     = 'MPG',
       x     = 'Weight',
       col   = 'Transmission',
       size  = 'Horsepower',
       title = 'MPG vs. Weight') +
  facet_wrap(~ gear) + 
  theme_light() + 
  theme(panel.grid.minor   = element_blank(),
        panel.grid.major.x = element_blank())
```


### `dplyr`

The `dplyr` library provides aggregation tools for data management. The following is an example of calculating the mean and median MPG by gear.

For more information, see the [`dplyr` website](https://dplyr.tidyverse.org/).

```{r}
my_agg <- mtcars %>%
  select(mpg, gear) %>%
  group_by(gear) %>%
  summarise(mean_mpg = mean(mpg),
            median_mpg = median(mpg))

my_agg
```


### `tidyr`

The `tidyr` library provides pivoting tools to reshape your dataset. The following are examples of how to reformat an aggregation from `dplyr`'s functions.

For more information, see the [`tidyr` website]( https://tidyr.tidyverse.org/).

```{r}
# Aggregation
my_agg <- mtcars %>%
  select(mpg, gear, am) %>%
  group_by(gear, am) %>%
  summarise(mean_mpg = mean(mpg))

# Pivot wide
my_agg2 <- my_agg %>%
  pivot_wider(id_cols     = gear, # rows
              names_from  = am, # columns
              values_from = mean_mpg) # values

my_agg2
```

```{r}
# Pivot long
my_agg2 %>%
  pivot_longer(2:3,
               names_to  = 'am',
               values_to = 'mpg',
               values_drop_na = TRUE) # drop NA values
```

### `purrr`

The `purrr` library offers functionals similar to the `*apply()` functions (the former's `map()` operates similarly as the latter's `lapply()`); however, the former contains functions that maintain type consistency. For example, there is a function called `map_dbl()` that throws an error if the output is not a double vector (i.e., a numeric vector), which is useful when you want to catch your program's errors.

The following are some examples from `purrr`. For more information on how to use these and other functions within the library, see the [`purrr` website](https://purrr.tidyverse.org/).

```{r}
map(mtcars, mean) # == lapply(mtcars, mean)

map_dbl(mtcars, mean) # == sapply(mtcars, mean)

map_df(mtcars, mean) # Maintains data frame class.
```


## `knitr`

The `knitr` library is an "engine for dynamic report generation," which allows for better formatted tables and documentation capabilities when using R Markdown.[^4] The following example demonstrates `kable()` to format a table.

[^4]: https://yihui.org/knitr/

```{r eval = FALSE}
install.packages('knitr')
```

```{r}
library(knitr)

my_table <- with(mtcars, table(gear, am))

kable(my_table)
```


## `stargazer`

The `stargazer` library allows one to format a regression model to be closer to journal-quality guidelines.

For more information, see [its documentation on CRAN](https://CRAN.R-project.org/package=stargazer).

```{r eval = FALSE}
install.packages('stargazer')
```

```{r}
library(stargazer)

my_ols <- lm(mpg ~ wt + hp + disp + gear + am, mtcars)
```

If you are using RGui or R Studio and not R Markdown, I recommend to set `type = 'text'` so that only textual output will be produced instead of LaTeX or HTML code.

```{r}
# If NOT using R Markdown...
stargazer(my_ols, type = 'text')
```

If you happen to use R Markdown, then set `type = 'html'` for HTML documents and omit `type` for PDF documents.

For more on R Markdown, see [the R Markdown book by Yihui Xie, J. J. Allaire, and Garrett Grolemund](https://bookdown.org/yihui/rmarkdown/).

```{r, results = 'asis'}
# If using RMarkdown...
stargazer(my_ols, type = 'html') # for html documents.
#stargazer(my_ols) # for PDF documents.
```

## Summary

```{r, echo = FALSE}
summ_libs <- data.frame(Library = c('ggplot2',
                                    'dplyr',
                                    'tidyr',
                                    'purrr',
                                    'knitr',
                                    'stargazer'),
                        Function = c("ggplot(data) + aes(y, x, ...) + geom_point()",
                                     "select(), group_by(), summarise()",
                                     "pivot_wider(), pivot_longer()",
                                     "map(.x, .f)",
                                     "kable(x)",
                                     "stargazer(x)"),
                        Description = c("Scatter plot with ggplot2.",
                                     "Select, group by, and summarise data.",
                                     "Pivot data long or wide.",
                                     "Apply a function over a data's elements iteratively.",
                                     "Format a table.",
                                     "Format a regression."),
                        Example = c('ggplot(mtcars) + 
  aes(y = mpg, x = wt, col = factor(am), size = hp) + 
  geom_point(alpha = 0.5)',
  "mtcars %>%
  select(mpg, gear) %>%
  group_by(gear) %>%
  summarise(mean_mpg = mean(mpg),
            median_mpg = median(mpg))",
  "my_agg <- mtcars %>%
  select(mpg, gear, am) %>%
  group_by(gear, am) %>%
  summarise(mean_mpg = mean(mpg))

my_agg2 <- my_agg %>%
  pivot_wider(id_cols     = gear, 
              names_from  = am,
              values_from = mean_mpg)
",
  "map(mtcars, mean)",
  "my_table <- with(mtcars, table(gear, am))

kable(my_table)",
  "my_ols <- lm(mpg ~ wt + hp + disp + gear + am, mtcars)

stargazer(my_ols, type = 'text')"))

summ(summ_libs, 'Summary of Recommended Libraries')
```


# Conclusion

I hope that these chapters were helpful in teaching you the concepts and syntax structure of R functions. This book is the first time I am writing something akin to a textbook: most of my writing have been academic papers, documentation for my packages[^5], and blog posts[^6], so I hope you have learned at least as much on R as I have on writing this book!

For further reading, I recommend reviewing the *References* and *Resources* sections, as they provide packages, data, and a book for practicing with and learning about R.

[^5]: https://github.com/robertschnitman
[^6]: https://robertschnitman.netlify.com/

# References {-}

`dplyr`. https://dplyr.tidyverse.org/

`ggplot2`. https://ggplot2.tidyverse.org/

Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. https://CRAN.R-project.org/package=stargazer

`Hmisc`. https://www.rdocumentation.org/packages/Hmisc/versions/4.3-1

`knitr`. https://yihui.org/knitr/

`purrr`. https://purrr.tidyverse.org/

RStudio Cheat Sheets. *strings.* Github. https://github.com/rstudio/cheatsheets/blob/master/strings.pdf

Schnitman, Robert. Github Profile. https://github.com/robertschnitman

---. Profile and Services. https://robertschnitman.netlify.com/

`stringr`. https://stringr.tidyverse.org/

`tidyr`. https://tidyr.tidyverse.org/

`tidyverse`. https://www.tidyverse.org/

Wikipedia. Small multiple. https://en.wikipedia.org/wiki/Small_multiple 

Xie, Yihui, J. J. Allaire, & Garrett Grolemund (2019). R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/

# Resources {-}

**1. [UNdata](http://www.google.com/url?q=http%3A%2F%2Fdata.un.org%2F&sa=D&sntz=1&usg=AFQjCNH0Z25jyA0bwqzYhuzylmB4y2cb0w) (United Nations' statistical database)**

UNdata provides international statistics hosted by the United Nations Statistics Division. It provides general regional profiles that summarize basic demographic, economic, and health data of countries, as well as time-series tables for historical analyses. Highly recommended for social scientists, public policy analysts, and other similar professions.


**2. [Institute for Digital Research and Education (idre), University of California at Los Angeles](http://www.google.com/url?q=http%3A%2F%2Fwww.ats.ucla.edu%2Fstat%2F&sa=D&sntz=1&usg=AFQjCNHwdJ9tBZh0VHNQroDiARMWa_f-Qg)**

The Institute has tutorial videos, annotated command outputs, workshop notes, and more for those wanting to learn and improve their skills in Stata, SPSS, SAS, and R. They emphasize applications while explaining the statistical theories behind them. Highly recommended as introductory material to these software.


**3. [R for Data Science (Hadley Wickham & Garrett Grolemund, 2017)](http://www.google.com/url?q=http%3A%2F%2Fr4ds.had.co.nz%2Findex.html&sa=D&sntz=1&usg=AFQjCNEh6DQtkOocX249isJVh0kN_CXXUw)**

Wickham and Grolemund's R for Data Science book teaches a select number of indispensable tools for data preparation, visualization, and reporting. Particularly, they demonstrate the dplyr library for transformations, ggplot2 for professional graphics, and R Markdown for presentable documentation. A must-read for anyone working with the R programming language.


**4. [LibreOffice: The Document Foundation](https://www.google.com/url?q=https%3A%2F%2Fwww.libreoffice.org%2F&sa=D&sntz=1&usg=AFQjCNH2tztP7Nv5-GRLblJMPpQi2_d6YA) (free open-source equivalent to Microsoft Office)**

Microsoft Office is ubiquitous. While its cost is a non-issue for large organizations, for others, however, even its cheapest options are expensive. Fortunately, LibreOffice offers suites that function the same, such as its Writer Document (Word equivalent) and Calc Spreadsheet (Excel equivalent). Notably, the Math Formula suite incorporates a formula editor that makes users be able to type complex mathematical equations at a faster rate than the cumbersome point-and-click method in Word. Additionally, LibreOffice's Access-equivalent Base boasts formal SQL scripting abilities and Wizard functions that guide the database design process. Recommended for students, work-at-home users, and smaller organizations wishing to cut costs.

**5. [bookdown.org](https://bookdown.org/)**

Bookdown.org is a site containing free online books about R. Notably, the *bookdown* book teaches you how to create your own books in R with the `bookdown` package (this book you're reading was created with this package!). Highly recommended for R users of any level, beginner through expert.

# About the Author {-}

Hello, I'm Robert Schnitman! I am an independent contractor providing statistical consulting and data analysis services to organizations and individuals. My services include preparing statistical reports, restructuring datasets, and creating visualizations. On the side, I blog primarily about R and data analysis on my website at https://robertschnitman.netlify.com/.

Feel free to contact me using the following links!

**Email:** robertschnitman@gmail.com

**LinkedIn:** https://www.linkedin.com/in/rschnitman/

**Github:** https://github.com/robertschnitman/